# machine-learning-fundamentals

Machine Learning Fundamentals

- **Gradient descent**

  - is a method to optimize your linear models.

- **Multiple Linear Regression**

  - is a technique for when you are comparing more than two variables.

- **Polynomial Regression**

  - is for relationships between variables that aren't linear.

- **Regularization**

  - is a technique to assure that your models will not only fit to the data available, but also extend to new situations.

- **Regression Problem**
  - predicting quantitative values. Predicting quantitative values is often just considered a Regression problem.

## Book

[Deep Learning Book, Ian Goodfellow](https://www.deeplearningbook.org/)

## ML FUNDAMENTALS

1. INTRO TO MACHINE LEARNING

   - 1. What Is Machine Learning?
   - 2. Projects

2. Intro

   - 1. Python Installation
   - 2. [For Windows] Configuring Git Bash to Run Python
   - 3. What is Anaconda?
   - 11. Installing Anaconda
   - 12. Managing packages
   - 13. On Python versions at Udacity
   - 14. Running a Python Script
   - 15. Programming Environment Setup
   - 16. What are Jupyter notebooks?
   - 17. Installing Jupyter Notebook
   - 18. Launching the notebook server
   - 19. Notebook interface
   - 20. Markdown cells
   - 21. Code cells
   - 22. Keyboard shortcuts
   - 23. Magic keywords
   - 24. Converting notebooks
   - 25. Creating a slideshow
   - 26. Outro

## SUPERVISED LEARNING

### LESSON 1: Machine Learning Bird's Eye View

- 1.  Introduction
- 2.  History - A Statistician's Perspective
- 3.  History - A Computer Scientist's Perspective
- 4.  Types of Machine Learning - Supervised
- 5.  Types of Machine Learning - Unsupervised & Reinforcement
- 6.  Deep Learning
- 7.  Scikit Learn
- 8.  Ethics in Machine Learning
- 9.  What's Ahead
- 10. Text: Recap

### LESSON 2: Linear Regression

- 1.  Intro
- 2.  Quiz: Housing Prices
- 3.  Solution: Housing Prices
- 4.  Fitting a Line Through Data
- 5.  Moving a Line
- 6.  Absolute Trick
- 7.  Square Trick
- 8.  Quiz: Absolute and Square Trick
- 9.  Gradient Descent
- 10. Mean Absolute Error
- 11. Mean Squared Error
- 12. Quiz: Mean Absolute & Squared Errors
- 13. Minimizing Error Functions
- 14. Mean vs Total Error
- 15. Mini-batch Gradient Descent
- 16. Quiz: Mini-Batch Gradient Descent
- 17. Absolute Error vs Squared Error
- 18. Linear Regression in Scikit learn
- 19. Higher Dimensions
- 20. Multiple Linear Regression
- 21. Closed Form Solution
- 22. (Optional) Closed form Solution Math
- 23. Linear Regression Warnings
- 24. Polynomial Regression
- 25. Quiz: Polynomial Regression
- 26. Regularization
- 27. Quiz: Regularization
- 28. Feature Scaling
- 29. Outro

### LESSON 3: Perceptron Algorithm

- 1. Intro
- 2.  Classification Problems 1
- 3.  Classification Problems 2
- 4.  Linear Boundaries
- 5.  Higher Dimensions
- 6.  Perceptrons
- 7.  Perceptrons as Logical Operators
- 8.  Perceptron Trick
- 9.  Perceptron Algorithm
- 10. Outro

### LESSON 4: Decision Trees

- 1.  Instructor
- 2.  Introduction
- 3.  Classification Problems 1
- 4.  Classification Problems 2
- 5.  Linear Boundaries
- 6.  Higher Dimensions
- 7.  Perceptrons
- 8.  Why "Neural Networks"?
- 9.  Perceptrons as Logical Operators
- 10. Perceptron Trick
- 11. Perceptron Algorithm
- 12. Non-Linear Regions
- 13. Error Functions
- 14. Log-loss Error Function
- 15. Discrete vs Continuous
- 16. Softmax
- 17. One-Hot Encoding
- 18. Maximum Likelihood
- 19. Maximizing Probabilities
- 20. Cross-Entropy 1
- 21. Cross-Entropy 2
- 22. Multi-Class Cross Entropy
- 23. Logistic Regression
- 24. Gradient Descent
- 25. Logistic Regression Algorithm
- 26. Pre-Lab: Gradient Descent
- 27. Notebook: Gradient Descent
- 28. Perceptron vs Gradient Descent
- 29. Continuous Perceptrons
- 30. Non-linear Data
- 31. Non-Linear Models
- 32. Neural Network Architecture
- 33. Feedforward
- 34. Backpropagation
- 35. Pre-Lab: Analyzing Student Data
- 36. Notebook: Analyzing Student Data
- 37. Outro

### LESSON 5: Naive Bayes

- 1.  Mean Squared Error Function
- 2.  Gradient Descent
- 3.  Gradient Descent: The Math
- 4.  Gradient Descent: The Code
- 5.  Implementing Gradient Descent
- 6.  Multilayer Perceptrons
- 7.  Backpropagation
- 8.  Implementing Backpropagation
- 9.  Further Reading

### LESSON 6: Support Vector Machines

- 1. Instructor
- 2.  Training Optimization
- 3.  Testing
- 4.  Overfitting and Underfitting
- 5.  Early Stopping
- 6.  Regularization
- 7.  Regularization 2
- 8.  Dropout
- 9.  Local Minima
- 10. Random Restart
- 11. Vanishing Gradient
- 12. Other Activation Functions
- 13. Batch vs Stochastic Gradient Descent
- 14. Learning Rate Decay
- 15. Momentum
- 16. Error Functions Around the World

### LESSON 7: Ensemble Methods

- 1. Intro
- 2. Ensembles
- 3. Random Forests
- 4. Bagging
- 5. AdaBoost
- 6. Weighting the Data
- 7. Weighting the Models 1
- 8. Weighting the Models 2

1. - 140. Welcome

- 141.  Pre-Notebook
- 142.  Notebook Workspace
- 143.  Single layer neural networks
- 144.  Single layer neural networks solution
- 145.  Networks Using Matrix Multiplication
- 146.  Multilayer Networks Solution
- 147.  Neural Networks in PyTorch
- 148.  Neural Networks Solution
- 149.  Implementing Softmax Solution
- 150.  Network Architectures in PyTorch
- 151.  Network Architectures Solution
- 152.  Training a Network Solution
- 153.  Classifying Fashion-MNIST
- 154.  Fashion-MNIST Solution
- 155.  Inference and Validation
- 156.  Validation Solution
- 157.  Dropout Solution
- 158.  Saving and Loading Models
- 159.  Loading Image Data
- 160.  Loading Image Data Solution
- 161.  Pre-Notebook with GPU
- 162.  Notebook Workspace w/ GPU
- 163.  A Note on Transfer Learning
- 164.  Transfer Learning
- 165.  Transfer Learning II
- 166.  Transfer Learning Solution
- 167.  Tips, Tricks, and Other Notes

11. - 168. Project Intro
    - 169. Introduction to GPU Workspaces
    - 170. Image Classifier - Part 1 - Development
    - 171. Image Classifier - Part 1 - Workspace
    - 172. Image Classifier - Part 2 - Command Line App
    - 173. Image Classifier - Part 2 - Workspace
    - 174. Rubric
    - 175. Project: Create Your Own Image Cl

12. - 176. Self-Reflection: Design Your Blueprint for Success
    - 177. Debrief: Self-Reflection Exercise Part 1
    - 178. Debrief: Self-Reflection Exercise Part 2
    - 179. Map Your Career Journey
    - 180. Debrief: Map Your Career Journey
    - 181. Conduct an Informational Interview
    - 182. How to Request an Informational Interview
    - 183. Ways to Connect
    - 184. Ask Good Questions
    - 185. Debrief: Sample Questions Quiz
    - 186. Keep the Conversation Going

13. UNSUPERVISED LEARNING

    - 188. Video: Introduction
    - 189. Text: Course Outline
    - 190. Video: Two Types of Unsupervised Learning
    - 191. Video: K-Means Use Cases
    - 192. Video: K-Means
    - 193. Quiz: Identifying Clusters
    - 194. Video: Changing K
    - 195. Video: Elbow Method
    - 196. Screencast: K-Means in Scikit Learn
    - 197. Notebook: Your Turn
    - 198. Screencast: Solution
    - 199. Video: How Does K-Means Work?
    - 200. Screencast + Text: How Does K-Means Work?
    - 201. Quiz: How Does K-Means Work?
    - 202. Video: Is that the Optimal Solution?
    - 203. Video: Feature Scaling
    - 204. Video: Feature Scaling Example
    - 205. Notebook: Feature Scaling Example
    - 206. Notebook: Feature Scaling
    - 207. Screencast: Solution
    - 208. Video: Outro
    - 209. Text: Recap

14. - 210. K-means considerations
    - 211. Overview of other clustering methods
    - 212. Hierarchical clustering: single-link
    - 213. Examining single-link clustering
    - 214. Complete-link, average-link, Ward
    - 215. Hierarchical clustering implementation
    - 216. [Lab] Hierarchical clustering
    - 217. [Lab Solution] Hierarchical Clustering
    - 218. HC examples and applications
    - 219. Quiz: [Quiz] Hierarchical clustering
    - 220. DBSCAN
    - 221. DBSCAN implementation
    - 222. [Lab] DBSCAN
    - 223. [Lab Solution] DBSCAN
    - 224. DBSCAN examples & applications
    - 225. Quiz: [Quiz] DBSCAN

15. - 226. Intro
    - 227. Gaussian Mixture Model (GMM) Clustering
    - 229. Gaussian Distribution in One Dimension
    - 230. GMM Clustering in One Dimension
    - 231. Gaussian Distribution in 2D
    - 232. GMM in 2D
    - 233. Quiz: Gaussian Mixtures
    - 234. Overview of The Expectation Maximization (EM) Algorithm
    - 235. Expectation Maximization Part 1
    - 236. Expectation Maximization Part 2
    - 237. Visual Example of EM Progress
    - 238. Quiz: Expectation Maximization
    - 239. GMM Implementation
    - 240. GMM Examples & Applications
    - 241. Cluster Analysis Process
    - 242. Cluster Validation
    - 243. External Validation Indices
    - 244. Quiz: Adjusted Rand Index
    - 245. Internal Validation Indices
    - 246. Quiz: Silhouette Coefficient
    - 247. GMM & Cluster Validation Lab
    - 248. GMM & Cluster Validation Lab Solu

16. - 249. Video: Introduction
    - 250. Video: Lesson Topics
    - 251. Text: Lesson Topics
    - 252. Video: Latent Features
    - 253. Latent Features
    - 254. Video: How to Reduce Features?
    - 255. Video: Dimensionality Reduction
    - 256. Video: PCA Properties
    - 257. Quiz: How Does PCA Work?
    - 258. Screencast: PCA
    - 259. Notebook: PCA - Your Turn
    - 260. Screencast: PCA Solution
    - 261. Screencast: Interpret PCA Results
    - 262. Notebook: Interpretation
    - 263. Screencast: Interpretation Solution
    - 264. Text: What Are EigenValues & EigenVectors?
    - 265. Video: When to Use PCA?
    - 266. Video: Recap
    - 267. Notebook: Mini-Project
    - 268. Mini-Project Solution
    - 269. Video: Outro
    - 270. Text: Recap

17. - 271. Random Projection
    - 272. Quiz: Random Projection
    - 273. Random Projection in sklearn
    - 274. Independent Component Analysis (ICA)
    - 275. FastICA Algorithm
    - 276. Quiz: ICA
    - 277. ICA in sklearn
    - 278. [Lab] Independent Component Analysis
    - 279. [Solution] Independent Component Analysis
    - 280. ICA Applications

18. - 281. Project Introduction
    - 282. Project Overview
    - 283. Project Details
    - 284. Arvato: Terms and Conditions
    - 285. Project Workspace
    - 286. Project: Creating Customer Segment

19. CONGRATULATIONS
